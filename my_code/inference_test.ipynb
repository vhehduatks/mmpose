{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import logging\n",
    "import mimetypes\n",
    "import os\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import cv2\n",
    "import json_tricks as json\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "from mmengine.logging import print_log\n",
    "\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "\n",
    "try:\n",
    "\tfrom mmdet.apis import inference_detector, init_detector\n",
    "\thas_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "\thas_mmdet = False\n",
    "\n",
    "\n",
    "from mmengine.config import Config, ConfigDict\n",
    "from typing import Union\n",
    "from mmcv.transforms import Compose\n",
    "from typing import Optional, Sequence, Union\n",
    "from mmcv.ops import RoIPool\n",
    "\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = r'C:\\Users\\user\\Documents\\GitHub\\mmpose\\temp_modify\\custom_config\\HMD_mo2cap2_config.py'\n",
    "model_ckpt = r'C:\\Users\\user\\Documents\\GitHub\\mmpose\\temp_modify\\work_dirs\\HMD_mo2cap2\\epoch_3.pth'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: C:\\Users\\user\\Documents\\GitHub\\mmpose\\temp_modify\\work_dirs\\HMD_mo2cap2\\epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "# build pose estimator\n",
    "pose_estimator = init_pose_estimator(\n",
    "\tmodel_config,\n",
    "\tmodel_ckpt,\n",
    "\tdevice=device,\n",
    "\t# cfg_options=dict(\n",
    "\t# \tmodel=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap)))\n",
    "\t)\n",
    "visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: C:\\Users\\user\\Documents\\GitHub\\mmpose\\temp_modify\\custom_config\\HMD_mo2cap2_config.py): {'default_scope': 'mmpose', 'default_hooks': {'checkpoint': {'type': 'CheckpointHook', 'interval': 10, 'max_keep_ckpts': 3}, 'visualization': {'type': 'PoseVisualizationHook', 'enable': True, 'interval': 15, 'kpt_thr': 0.3}}, 'custom_hooks': [{'type': 'SyncBuffersHook'}], 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'log_processor': {'type': 'LogProcessor', 'window_size': 50, 'by_epoch': True, 'num_digits': 6}, 'log_level': 'INFO', 'load_from': None, 'resume': False, 'backend_args': {'backend': 'local'}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 10, 'val_interval': 1, 'dynamic_intervals': [(280, 1)]}, 'val_cfg': {}, 'test_cfg': {}, 'auto_scale_lr': {'base_batch_size': 256}, 'optim_wrapper': {'optimizer': {'type': 'Adam', 'lr': 0.0005}}, 'param_scheduler': [{'type': 'LinearLR', 'begin': 0, 'end': 500, 'start_factor': 0.001, 'by_epoch': False}, {'type': 'MultiStepLR', 'begin': 0, 'end': 210, 'milestones': [170, 200], 'gamma': 0.1, 'by_epoch': True}], 'codec': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}, 'model': {'type': 'TopdownPoseEstimator', 'data_preprocessor': {'type': 'PoseDataPreprocessor', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'bgr_to_rgb': True}, 'backbone': {'type': 'ResNet', 'depth': 50, 'init_cfg': None}, 'head': {'type': 'CustomMo2Cap2HeatmapHead', 'in_channels': 2048, 'out_channels': 15, 'loss': {'type': 'KeypointMSELoss', 'use_target_weight': True, 'loss_weight': 1000}, 'loss_3d': {'type': 'MSELoss', 'use_target_weight': False, 'loss_weight': 10}, 'decoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, 'test_cfg': {'flip_test': True, 'flip_mode': 'heatmap', 'shift_heatmap': True, 'output_heatmaps': True}, 'train_cfg': None}, 'dataset_type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'data_root': 'C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\mmpose\\\\data', 'ann_file_test': 'F:\\\\mo2cap2_data_half\\\\TestSet', 'ann_file_val': 'F:\\\\mo2cap2_data_half\\\\ValSet', 'ann_file_train': 'F:\\\\mo2cap2_data_half\\\\TrainSet', 'train_pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'RandomFlip', 'direction': 'horizontal'}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'GenerateTarget', 'encoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, {'type': 'PackPoseInputs'}], 'val_pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'GenerateTarget', 'encoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, {'type': 'PackPoseInputs'}], 'test_pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'PackPoseInputs'}], 'dataset_mo2cap2_train': {'type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'ann_file': 'F:\\\\mo2cap2_data_half\\\\TrainSet', 'pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'RandomFlip', 'direction': 'horizontal'}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'GenerateTarget', 'encoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, {'type': 'PackPoseInputs'}]}, 'dataset_mo2cap2_val': {'type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'ann_file': 'F:\\\\mo2cap2_data_half\\\\ValSet', 'pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'GenerateTarget', 'encoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, {'type': 'PackPoseInputs'}], 'test_mode': False}, 'dataset_mo2cap2_test': {'type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'ann_file': 'F:\\\\mo2cap2_data_half\\\\TestSet', 'pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'PackPoseInputs'}], 'test_mode': True}, 'train_dataloader': {'batch_size': 64, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': True, 'drop_last': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}, 'dataset': {'type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'ann_file': 'F:\\\\mo2cap2_data_half\\\\TrainSet', 'pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'RandomFlip', 'direction': 'horizontal'}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'GenerateTarget', 'encoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, {'type': 'PackPoseInputs'}]}}, 'val_dataloader': {'batch_size': 32, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': True, 'round_up': False}, 'dataset': {'type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'ann_file': 'F:\\\\mo2cap2_data_half\\\\ValSet', 'pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'GenerateTarget', 'encoder': {'type': 'Custom_mo2cap2_MSRAHeatmap', 'input_size': (256, 256), 'heatmap_size': (64, 64), 'sigma': 2}}, {'type': 'PackPoseInputs'}], 'test_mode': False}}, 'test_dataloader': {'batch_size': 32, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': True, 'round_up': False}, 'dataset': {'type': 'Mo2Cap2CocoDataset', 'data_mode': 'topdown', 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'ann_file': 'F:\\\\mo2cap2_data_half\\\\TestSet', 'pipeline': [{'type': 'LoadImage'}, {'type': 'GetBBoxCenterScale', 'padding': 1.0}, {'type': 'TopdownAffine', 'input_size': (256, 256)}, {'type': 'PackPoseInputs'}], 'test_mode': True}}, 'val_evaluator': {'type': 'CustomMo2Cap2Metric', 'ann_file': None, 'use_action': False}, 'test_evaluator': {'type': 'CustomMo2Cap2Metric', 'ann_file': None, 'use_action': True}, 'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'WandbVisBackend', 'init_kwargs': {'project': 'mmpose_mo2cap2dataset'}}], 'visualizer': {'type': 'CustomPose3dLocalVisualizer', 'vis_backends': [{'type': 'LocalVisBackend', 'save_dir': None}, {'type': 'WandbVisBackend', 'init_kwargs': {'project': 'mmpose_mo2cap2dataset'}, 'save_dir': None}], 'name': 'visualizer'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_estimator.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.set_dataset_meta(\n",
    "\tpose_estimator.dataset_meta, skeleton_style='mo2cap2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "\t'det_config': 'path/to/det_config',  # detection 설정 파일 경로\n",
    "\t'det_checkpoint': 'path/to/det_checkpoint',  # detection 체크포인트 파일 경로\n",
    "\t'pose_config': 'path/to/pose_config',  # 포즈 설정 파일 경로\n",
    "\t'pose_checkpoint': 'path/to/pose_checkpoint',  # 포즈 체크포인트 파일 경로\n",
    "\t'input': '',  # 이미지/비디오 파일 경로\n",
    "\t'show': False,  # 이미지를 표시할지 여부\n",
    "\t'output_root': '',  # 출력 이미지 파일 루트 경로\n",
    "\t'save_predictions': False,  # 예측 결과를 저장할지 여부\n",
    "\t'device': 'cuda:0',  # 추론에 사용할 장치\n",
    "\t'det_cat_id': 0,  # 바운딩 박스 탐지 모델의 카테고리 ID\n",
    "\t'bbox_thr': 0.3,  # 바운딩 박스 점수 임계값\n",
    "\t'nms_thr': 0.3,  # 바운딩 박스 NMS를 위한 IoU 임계값\n",
    "\t'kpt_thr': 0.3,  # 키포인트 시각화 임계값\n",
    "\t'draw_heatmap': False,  # 모델이 예측한 히트맵을 그릴지 여부\n",
    "\t'show_kpt_idx': False,  # 키포인트의 인덱스를 표시할지 여부\n",
    "\t'skeleton_style': 'mmpose',  # 스켈레톤 스타일 선택\n",
    "\t'radius': 3,  # 시각화할 키포인트 반경\n",
    "\t'thickness': 1,  # 시각화할 링크 두께\n",
    "\t'show_interval': 0,  # 프레임당 대기 시간 (초)\n",
    "\t'alpha': 0.8,  # 바운딩 박스의 투명도\n",
    "\t'draw_bbox': False,  # 인스턴스의 바운딩 박스를 그릴지 여부\n",
    "\t'Visualizer':'CustomPose3dLocalVisualizer',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'LoadImage'},\n",
       " {'type': 'GetBBoxCenterScale', 'padding': 1.0},\n",
       " {'type': 'TopdownAffine', 'input_size': (256, 256)},\n",
       " {'type': 'PackPoseInputs'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_test_pipeline_cfg(cfg: Union[str, ConfigDict]) -> ConfigDict:\n",
    "    \"\"\"Get the test dataset pipeline from entire config.\n",
    "\n",
    "    Args:\n",
    "        cfg (str or :obj:`ConfigDict`): the entire config. Can be a config\n",
    "            file or a ``ConfigDict``.\n",
    "\n",
    "    Returns:\n",
    "        :obj:`ConfigDict`: the config of test dataset.\n",
    "    \"\"\"\n",
    "    if isinstance(cfg, str):\n",
    "        cfg = Config.fromfile(cfg)\n",
    "\n",
    "    def _get_test_pipeline_cfg(dataset_cfg):\n",
    "        if 'pipeline' in dataset_cfg:\n",
    "            return dataset_cfg.pipeline\n",
    "        # handle dataset wrapper\n",
    "        elif 'dataset' in dataset_cfg:\n",
    "            return _get_test_pipeline_cfg(dataset_cfg.dataset)\n",
    "        # handle dataset wrappers like ConcatDataset\n",
    "        elif 'datasets' in dataset_cfg:\n",
    "            return _get_test_pipeline_cfg(dataset_cfg.datasets[0])\n",
    "\n",
    "        raise RuntimeError('Cannot find `pipeline` in `test_dataloader`')\n",
    "\n",
    "    return _get_test_pipeline_cfg(cfg.test_dataloader.dataset)\n",
    "\n",
    "get_test_pipeline_cfg(pose_estimator.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagesType = Union[str, np.ndarray, Sequence[str], Sequence[np.ndarray]]\n",
    "\n",
    "def inference_detector(\n",
    "    # model: nn.Module,\n",
    "    imgs: ImagesType,\n",
    "    test_pipeline: Optional[Compose] = None,\n",
    "    text_prompt: Optional[str] = None,\n",
    "    custom_entities: bool = False,\n",
    "):\n",
    "    \"\"\"Inference image(s) with the detector.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded detector.\n",
    "        imgs (str, ndarray, Sequence[str/ndarray]):\n",
    "           Either image files or loaded images.\n",
    "        test_pipeline (:obj:`Compose`): Test pipeline.\n",
    "\n",
    "    Returns:\n",
    "        :obj:`DetDataSample` or list[:obj:`DetDataSample`]:\n",
    "        If imgs is a list or tuple, the same length list type results\n",
    "        will be returned, otherwise return the detection results directly.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(imgs, (list, tuple)):\n",
    "        is_batch = True\n",
    "    else:\n",
    "        imgs = [imgs]\n",
    "        is_batch = False\n",
    "\n",
    "    # cfg = model.cfg\n",
    "\n",
    "    if test_pipeline is None:\n",
    "        # cfg = cfg.copy()\n",
    "        test_pipeline = get_test_pipeline_cfg(pose_estimator.cfg)\n",
    "        if isinstance(imgs[0], np.ndarray):\n",
    "            # Calling this method across libraries will result\n",
    "            # in module unregistered error if not prefixed with mmdet.\n",
    "            test_pipeline[0].type = 'mmdet.LoadImageFromNDArray'\n",
    "\n",
    "        test_pipeline = Compose(test_pipeline)\n",
    "\n",
    "    # if model.data_preprocessor.device.type == 'cpu':\n",
    "    #     for m in model.modules():\n",
    "    #         assert not isinstance(\n",
    "    #             m, RoIPool\n",
    "    #         ), 'CPU inference with RoIPool is not supported currently.'\n",
    "\n",
    "    result_list = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        # prepare data\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # TODO: remove img_id.\n",
    "            data_ = dict(img=img, img_id=0)\n",
    "        else:\n",
    "            # TODO: remove img_id.\n",
    "            data_ = dict(img_path=img, img_id=0)\n",
    "\n",
    "        if text_prompt:\n",
    "            data_['text'] = text_prompt\n",
    "            data_['custom_entities'] = custom_entities\n",
    "\n",
    "        # build the data pipeline\n",
    "        data_ = test_pipeline(data_)\n",
    "\n",
    "        data_['inputs'] = [data_['inputs']]\n",
    "        data_['data_samples'] = [data_['data_samples']]\n",
    "\n",
    "        # forward the model\n",
    "        # with torch.no_grad():\n",
    "        #     results = model.test_step(data_)[0]\n",
    "\n",
    "        # result_list.append(results)\n",
    "\n",
    "    if not is_batch:\n",
    "        return result_list[0]\n",
    "    else:\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_one_image(\n",
    "\t\t\t\t\targs,\n",
    "\t\t\t\t\timg,\n",
    "\t\t\t\t\t# detector,\n",
    "\t\t\t\t\tpose_estimator,\n",
    "\t\t\t\t\tvisualizer=None,\n",
    "\t\t\t\t\tshow_interval=0\n",
    "\t\t\t\t\t):\n",
    "\t\"\"\"Visualize predicted keypoints (and heatmaps) of one image.\"\"\"\n",
    "\n",
    "\t# predict bbox\n",
    "\t# det_result = inference_detector(img)\n",
    "\t# pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\t# img = Image.open(img)\n",
    "\t# w,h = img.size\n",
    "\n",
    "\t# bboxes = [0,0,w,h]\n",
    "\n",
    "\t# bboxes = np.concatenate(\n",
    "\t# \t(pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "\t# bboxes = bboxes[np.logical_and(pred_instance.labels == args['det_cat_id'],\n",
    "\t# \t\t\t\t\t\t\t   pred_instance.scores > args['bbox_thr'])]\n",
    "\t# bboxes = bboxes[nms(bboxes, args['nms_thr']), :4]\n",
    "\t'''\n",
    "\tbbox_format (str): The bbox format indicator. Options are ``'xywh'``\n",
    "\t\tand ``'xyxy'``. Defaults to ``'xyxy'``\n",
    "\t'''\n",
    "\t# predict keypoints\n",
    "\tpose_results = inference_topdown(pose_estimator, img)\n",
    "\tdata_samples = merge_data_samples(pose_results)\n",
    "\n",
    "\t# show the results\n",
    "\tif isinstance(img, str):\n",
    "\t\timg = mmcv.imread(img, channel_order='rgb')\n",
    "\telif isinstance(img, np.ndarray):\n",
    "\t\timg = mmcv.bgr2rgb(img)\n",
    "\n",
    "\tif visualizer is not None:\n",
    "\t\tvisualizer.add_datasample(\n",
    "\t\t\t'result',\n",
    "\t\t\timage = img,\n",
    "\t\t\tdata_sample = data_samples,\n",
    "\t\t\tdraw_gt = False,\n",
    "\t\t\tdraw_pred = True,\n",
    "\t\t\tdraw_2d = True,\n",
    "\t\t\tdraw_bbox = False,\n",
    "\t\t\tshow_kpt_idx = False,\n",
    "\t\t\tskeleton_style = 'mmpose',\n",
    "\t\t\tdataset_2d = 'coco',\n",
    "\t\t\tdataset_3d = 'coco',\n",
    "\t\t\tconvert_keypoint = False,\n",
    "\t\t\taxis_azimuth = 80,\n",
    "\t\t\taxis_limit = 1.7,\n",
    "\t\t\taxis_dist = 10.0,\n",
    "\t\t\taxis_elev = -170.0,\n",
    "\t\t\tnum_instances = -1,\n",
    "\t\t\tshow = True,\n",
    "\t\t\twait_time = 0,\n",
    "\t\t\tout_file = None,\n",
    "\t\t\tkpt_thr = 0.3,\n",
    "\t\t\tstep = 0) \n",
    "\n",
    "\t# if there is no instance detected, return None\n",
    "\treturn data_samples.get('pred_instances', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.0 80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<InstanceData(\n",
       "\n",
       "    META INFORMATION\n",
       "\n",
       "    DATA FIELDS\n",
       "    bbox_scores: array([1.], dtype=float32)\n",
       "    keypoints: array([[[133., 199.],\n",
       "                [167., 185.],\n",
       "                [165., 159.],\n",
       "                [165., 141.],\n",
       "                [ 99., 179.],\n",
       "                [107., 157.],\n",
       "                [111., 141.],\n",
       "                [145., 153.],\n",
       "                [141., 143.],\n",
       "                [141., 143.],\n",
       "                [143., 135.],\n",
       "                [127., 153.],\n",
       "                [131., 143.],\n",
       "                [131., 143.],\n",
       "                [129., 135.]]], dtype=float32)\n",
       "    keypoint_scores: array([[0.9150333 , 0.8262009 , 0.7571056 , 0.78994286, 0.84088075,\n",
       "                0.8486061 , 0.7861284 , 0.8857001 , 0.65115947, 0.63794756,\n",
       "                0.5699916 , 0.9174322 , 0.7005327 , 0.68346334, 0.6202189 ]],\n",
       "              dtype=float32)\n",
       "    keypoints_visible: array([[0.9150333 , 0.8262009 , 0.7571056 , 0.78994286, 0.84088075,\n",
       "                0.8486061 , 0.7861284 , 0.8857001 , 0.65115947, 0.63794756,\n",
       "                0.5699916 , 0.9174322 , 0.7005327 , 0.68346334, 0.6202189 ]],\n",
       "              dtype=float32)\n",
       "    keypoint_3d: tensor([[[-0.1393,  0.1648,  0.2593],\n",
       "                 [ 0.1909,  0.2266,  0.2294],\n",
       "                 [ 0.4671,  0.0416,  0.4444],\n",
       "                 [ 0.3134,  0.0950,  0.5149],\n",
       "                 [-0.0596,  0.1668,  0.2023],\n",
       "                 [-0.2977,  0.2302,  0.6521],\n",
       "                 [-0.1934,  0.0769,  0.9100],\n",
       "                 [-0.0601,  0.2561,  0.8496],\n",
       "                 [ 0.2587,  0.0255,  1.1284],\n",
       "                 [ 0.2670,  0.0397,  1.6772],\n",
       "                 [ 0.0884, -0.0896,  1.5477],\n",
       "                 [-0.1145,  0.2542,  0.6602],\n",
       "                 [-0.1863,  0.1563,  1.0792],\n",
       "                 [-0.2666,  0.0873,  1.3798],\n",
       "                 [-0.0262, -0.1504,  1.6986]]], device='cuda:0')\n",
       "    bboxes: array([[  0.,   0., 256., 256.]], dtype=float32)\n",
       ") at 0x220a0068460>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_path = r'F:\\mo2cap2_data_temp_extracted\\TestSet\\weipeng_studio\\rgba\\frame_c_0_f_0387.png'\n",
    "train_img_path = r'F:\\mo2cap2_data_temp_extracted\\TrainSet\\mo2cap2_chunk_0002\\rgba\\mo2cap2_chunk_0002_000000.png'\n",
    "# inference\n",
    "pred_instances = process_one_image(args,train_img_path,pose_estimator, visualizer)\n",
    "pred_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if args.save_predictions:\n",
    "\tpred_instances_list = split_instances(pred_instances)\n",
    "\n",
    "if output_file:\n",
    "\timg_vis = visualizer.get_image()\n",
    "\tmmcv.imwrite(mmcv.rgb2bgr(img_vis), output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
